{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMULhLLFS5WDUhTy/ITCCpQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateon01/class2025Spring-mid-term/blob/main/fine_tun_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Model Fine-tuning\n",
        "\n",
        "This notebook demonstrates how to fine-tune a lightweight embedding model that can run efficiently on M1 Pro chips. We'll use data generated from Amazon Bedrock's Claude 3.5 Sonnet model for training our embedding model."
      ],
      "metadata": {
        "id": "_sFsS3VhmOPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup\n",
        "\n",
        "First, let's ensure we have the necessary dependencies installed."
      ],
      "metadata": {
        "id": "tsdHnhvZmTdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "W5vior9LviO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Python version\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Install required packages\n",
        "%pip install -q torch transformers datasets sentence-transformers evaluate scikit-learn pandas numpy matplotlib boto3 accelerate"
      ],
      "metadata": {
        "id": "npm0fqpjmKEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select a Lightweight Embedding Model\n",
        "\n",
        "For M1 Pro compatibility and efficiency, we'll use a lightweight embedding model from the Sentence Transformers library. Good candidates include:\n",
        "\n",
        "1. `all-MiniLM-L6-v2`: A compact model (80MB) that performs well for many tasks\n",
        "2. `paraphrase-MiniLM-L3-v2`: Even smaller (40MB) but still effective\n",
        "3. `all-mpnet-base-v2`: Higher quality but still runs efficiently on M1 Pro\n",
        "\n",
        "We'll use `all-MiniLM-L6-v2` as our base model for fine-tuning."
      ],
      "metadata": {
        "id": "ztoBP4aCmZQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Check if MPS (Metal Performance Shaders) is available for M1 acceleration\n",
        "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the base model\n",
        "model_name = \"all-MiniLM-L6-v2\"\n",
        "model = SentenceTransformer(model_name)\n",
        "model.to(device)\n",
        "\n",
        "print(f\"Model loaded: {model_name}\")\n",
        "print(f\"Model size: {sum(p.numel() for p in model.parameters())} parameters\")"
      ],
      "metadata": {
        "id": "VlqWpMvomZne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Data Load"
      ],
      "metadata": {
        "id": "LpzoZWV4v76x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import InputExample\n",
        "\n",
        "# data 디렉토리에서 모든 jsonl 파일 찾기\n",
        "jsonl_files = glob.glob('data/*.jsonl')\n",
        "print(f\"찾은 JSONL 파일 목록: {jsonl_files}\")\n",
        "\n",
        "# 문장 쌍 데이터를 담을 리스트\n",
        "all_pairs = []\n",
        "\n",
        "# 각 파일 읽기\n",
        "for file_path in jsonl_files:\n",
        "    file_name = os.path.basename(file_path)\n",
        "\n",
        "    # JSONL 파일 읽기\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                record = json.loads(line.strip())\n",
        "                if 'sentence1' in record and 'sentence2' in record:\n",
        "                    all_pairs.append(record)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"파일 {file_name}의 라인 파싱 오류: {e}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"{file_name}에서 {len(all_pairs)}개 문장 쌍 누적 로드됨\")\n",
        "\n",
        "# 리스트를 데이터프레임으로 변환\n",
        "df_all = pd.DataFrame(all_pairs)\n",
        "\n",
        "# 기본 정보 출력\n",
        "print(f\"\\n총 로드된 문장 쌍: {len(df_all)}개\")\n",
        "if len(df_all) > 0:\n",
        "    print(f\"데이터 컬럼: {', '.join(df_all.columns)}\")\n",
        "    print(\"\\n샘플 데이터:\")\n",
        "    print(df_all.head(3))\n",
        "\n",
        "# 훈련 및 검증 세트 분할\n",
        "train_df, val_df = train_test_split(df_all, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\n훈련 샘플: {len(train_df)}개\")\n",
        "print(f\"검증 샘플: {len(val_df)}개\")\n",
        "\n",
        "# 훈련 예제 생성\n",
        "train_examples = []\n",
        "for _, row in train_df.iterrows():\n",
        "    train_examples.append(InputExample(\n",
        "        texts=[row['sentence1'], row['sentence2']])\n",
        "    )\n",
        "\n",
        "# 검증 예제 생성\n",
        "val_examples = []\n",
        "for _, row in val_df.iterrows():\n",
        "    val_examples.append(InputExample(\n",
        "        texts=[row['sentence1'], row['sentence2']])\n",
        "    )\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
        "val_dataloader = DataLoader(val_examples, shuffle=False, batch_size=16)\n",
        "\n",
        "print(f\"\\n훈련 데이터 로더 생성 완료: {len(train_dataloader)} 배치\")\n",
        "print(f\"검증 데이터 로더 생성 완료: {len(val_dataloader)} 배치\")"
      ],
      "metadata": {
        "id": "QZD_MY1wvswp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Training Data\n",
        "\n",
        "Now we'll prepare our dataset for fine-tuning the embedding model."
      ],
      "metadata": {
        "id": "9EPrSP0ivy7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train and validation sets\n",
        "train_df, val_df = train_test_split(df_all, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_df)}\")\n",
        "print(f\"Validation samples: {len(val_df)}\")\n",
        "\n",
        "# Create training examples\n",
        "train_examples = []\n",
        "for _, row in train_df.iterrows():\n",
        "    train_examples.append(InputExample(\n",
        "        texts=[row['sentence1'], row['sentence2']]))\n",
        "\n",
        "# Create validation examples\n",
        "val_examples = []\n",
        "for _, row in val_df.iterrows():\n",
        "    val_examples.append(InputExample(\n",
        "        texts=[row['sentence1'], row['sentence2']]))\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
        "val_dataloader = DataLoader(val_examples, shuffle=False, batch_size=16)"
      ],
      "metadata": {
        "id": "mcOH1kJ-oR2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune the Embedding Model\n",
        "\n",
        "Now we'll fine-tune our embedding model using the prepared data."
      ],
      "metadata": {
        "id": "A_t_ujvrv1S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "\n",
        "# Define the loss function (Multiple Negatives Ranking Loss)\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "\n",
        "# Create an evaluator\n",
        "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(val_examples)\n",
        "\n",
        "# Set up training parameters\n",
        "num_epochs = 5\n",
        "warmup_steps = int(len(train_dataloader) * 0.1)\n",
        "output_dir = \"./fine-tuned-embedding-model\"\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    evaluator=evaluator,\n",
        "    epochs=num_epochs,\n",
        "    warmup_steps=warmup_steps,\n",
        "    output_path=output_dir,\n",
        "    show_progress_bar=True\n",
        ")"
      ],
      "metadata": {
        "id": "DOTz1YYSv34t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Fine-tuned Model\n",
        "\n",
        "Let's evaluate our fine-tuned model on some test examples and then on the MTEB STS17 benchmark dataset."
      ],
      "metadata": {
        "id": "ta1zwwufwMQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 모델 이름 정의 (이전 셀에서 정의되었을 것으로 추정)\n",
        "# 만약 정의되지 않았다면, 원래 기본 모델 이름을 여기에 작성하세요\n",
        "model_name = \"all-MiniLM-L6-v2\"  # 예시 모델명 (실제 사용한 모델명으로 교체 필요)\n",
        "\n",
        "# 모델 저장 경로 지정 (이전 셀에서 정의된 변수일 수 있음)\n",
        "# 모델이 저장된 실제 경로를 지정해야 합니다 (data 폴더가 아님)\n",
        "# 예시 경로 (실제 모델 저장 경로로 교체 필요)\n",
        "output_dir = \"fine-tuned-embedding-model\"\n",
        "\n",
        "# 사용 가능한 디바이스 확인\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else\n",
        "                      (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 기본 모델 로드\n",
        "base_model = SentenceTransformer(model_name)\n",
        "base_model.to(device)\n",
        "print(f\"Base model loaded: {model_name}\")\n",
        "\n",
        "# 미세 조정된 모델을 직접 로드하려면 경로 확인이 필요합니다\n",
        "try:\n",
        "    # 1. 먼저 output_dir 경로를 사용하여 로드 시도\n",
        "    fine_tuned_model = SentenceTransformer(output_dir)\n",
        "    print(f\"Fine-tuned model loaded from: {output_dir}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error loading from {output_dir}: {e}\")\n",
        "\n",
        "    # 2. 대체 방법: output_dir 아래의 디렉토리 확인\n",
        "    import os\n",
        "    import glob\n",
        "\n",
        "    possible_model_dirs = glob.glob(f\"{output_dir}/**/\")\n",
        "    if possible_model_dirs:\n",
        "        for model_dir in possible_model_dirs:\n",
        "            try:\n",
        "                fine_tuned_model = SentenceTransformer(model_dir.rstrip('/'))\n",
        "                print(f\"Fine-tuned model loaded from: {model_dir}\")\n",
        "                break\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "    # 3. 여전히 실패하면 epoch 번호가 있는 폴더 시도\n",
        "    if 'fine_tuned_model' not in locals():\n",
        "        epoch_dirs = glob.glob(f\"{output_dir}/*-*/\")\n",
        "        if epoch_dirs:\n",
        "            latest_dir = sorted(epoch_dirs)[-1]  # 가장 마지막 epoch 디렉토리\n",
        "            try:\n",
        "                fine_tuned_model = SentenceTransformer(latest_dir.rstrip('/'))\n",
        "                print(\n",
        "                    f\"Fine-tuned model loaded from latest epoch: {latest_dir}\")\n",
        "            except ValueError as e:\n",
        "                print(f\"Error loading from {latest_dir}: {e}\")\n",
        "                # 4. 모든 시도 실패 시 예비책: 기본 모델을 미세 조정 모델로 사용\n",
        "                print(\n",
        "                    \"WARNING: Could not load fine-tuned model. Using base model as fallback.\")\n",
        "                fine_tuned_model = base_model\n",
        "\n",
        "# 모델을 디바이스로 이동\n",
        "fine_tuned_model.to(device)\n",
        "\n",
        "# 테스트 문장 쌍 생성\n",
        "test_pairs = [\n",
        "    (\"임베딩 모델은 텍스트를 수치 벡터로 변환합니다\",\n",
        "     \"텍스트 임베딩은 문장을 벡터 표현으로 변환합니다\"),\n",
        "    (\"파인 튜닝은 특정 작업에서 모델 성능을 향상시킵니다\",\n",
        "     \"작업 특화 훈련은 모델 정확도를 높입니다\"),\n",
        "    (\"클라우드 컴퓨팅은 확장 가능한 리소스를 제공합니다\",\n",
        "     \"클라우드 서비스는 확장 가능한 인프라를 제공합니다\"),\n",
        "    (\"파이썬은 인기 있는 프로그래밍 언어입니다\",\n",
        "     \"머신러닝 모델은 대규모 데이터가 필요합니다\")\n",
        "]\n",
        "\n",
        "# 기본 모델과 미세 조정 모델 비교\n",
        "results = []\n",
        "\n",
        "for sent1, sent2 in test_pairs:\n",
        "    # 기본 모델에서 임베딩 얻기\n",
        "    base_emb1 = base_model.encode(sent1, convert_to_tensor=True)\n",
        "    base_emb2 = base_model.encode(sent2, convert_to_tensor=True)\n",
        "    base_sim = torch.cosine_similarity(base_emb1, base_emb2, dim=0).item()\n",
        "\n",
        "    # 미세 조정 모델에서 임베딩 얻기\n",
        "    ft_emb1 = fine_tuned_model.encode(sent1, convert_to_tensor=True)\n",
        "    ft_emb2 = fine_tuned_model.encode(sent2, convert_to_tensor=True)\n",
        "    ft_sim = torch.cosine_similarity(ft_emb1, ft_emb2, dim=0).item()\n",
        "\n",
        "    results.append({\n",
        "        \"sentence1\": sent1,\n",
        "        \"sentence2\": sent2,\n",
        "        \"base_similarity\": base_sim,\n",
        "        \"fine_tuned_similarity\": ft_sim\n",
        "    })\n",
        "\n",
        "# 결과 표시\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df"
      ],
      "metadata": {
        "id": "w8VzFX0cwNDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "x = np.arange(len(results))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x - width/2, results_df['base_similarity'], width, label='Base Model')\n",
        "plt.bar(x + width/2,\n",
        "        results_df['fine_tuned_similarity'], width, label='Fine-tuned Model')\n",
        "\n",
        "plt.xlabel('Sentence Pairs')\n",
        "plt.ylabel('Cosine Similarity')\n",
        "plt.title('Comparison of Base vs Fine-tuned Embedding Model')\n",
        "plt.xticks(x, [f\"Pair {i+1}\" for i in range(len(results))])\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XXSkxt1NxwA7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}